# -*- coding: utf-8 -*-
import os
import mimetypes
import io
import wave
import json
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from supabase import create_client, Client

# å¾æˆ‘å€‘é‡æ§‹çš„æ¨¡çµ„ä¸­å°å…¥å‡½å¼å’Œé¡
from arxiv_search import search_latest_ai_paper
from podcast_generater import PaperPodcastGenerator, PaperInfo
from config import ARXIV_SEARCH_CONFIG, SUPABASE_CONFIG

def init_supabase_client() -> Client:
    """åˆå§‹åŒ–ä¸¦è¿”å› Supabase å®¢æˆ¶ç«¯"""
    load_dotenv()
    url = os.environ.get("SUPABASE_URL")
    key = os.environ.get("SUPABASE_KEY")
    if not url or not key:
        raise ValueError("Supabase URL å’Œ Key å¿…é ˆåœ¨ .env æ–‡ä»¶ä¸­è¨­å®š")
    return create_client(url, key)

def check_paper_exists(client: Client, arxiv_id: str) -> bool:
    """æª¢æŸ¥è«–æ–‡æ˜¯å¦å·²å­˜åœ¨æ–¼è³‡æ–™åº«ä¸­"""
    try:
        response = client.table("papers").select("id").eq("arxiv_id", arxiv_id).execute()
        return len(response.data) > 0
    except Exception as e:
        print(f"æª¢æŸ¥è«–æ–‡æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return False

def upload_to_storage(client: Client, bucket_name: str, destination_path: str, file_data: bytes) -> str:
    """ä¸Šå‚³äºŒé€²ä½è³‡æ–™åˆ° Supabase Storage ä¸¦è¿”å›å…¬é–‹ URL"""
    try:
        # æ ¹æ“šç›®æ¨™è·¯å¾‘çŒœæ¸¬ MIME é¡å‹ï¼Œä¾‹å¦‚ 'audio/wav'
        content_type, _ = mimetypes.guess_type(destination_path)
        options = {"contentType": content_type or "application/octet-stream"}

        # é¦–å…ˆå˜—è©¦æ›´æ–°ï¼ˆå¦‚æœæª”æ¡ˆå·²å­˜åœ¨ï¼‰
        try:
            client.storage.from_(bucket_name).update(path=destination_path, file=file_data, file_options=options)
            print(f"ğŸ”„ æˆåŠŸæ›´æ–° Storage ä¸­çš„æª”æ¡ˆ: {destination_path}")
        except Exception:
            # å¦‚æœæ›´æ–°å¤±æ•—ï¼ˆé€šå¸¸æ˜¯å› ç‚ºæª”æ¡ˆä¸å­˜åœ¨ï¼‰ï¼Œå‰‡ä¸Šå‚³æ–°æª”æ¡ˆ
            client.storage.from_(bucket_name).upload(path=destination_path, file=file_data, file_options=options)
            print(f"ğŸ”¼ æˆåŠŸä¸Šå‚³æ–°æª”æ¡ˆåˆ° Storage: {destination_path}")

        # ç²å–å…¬é–‹ URL
        response = client.storage.from_(bucket_name).get_public_url(destination_path)
        return response
    except Exception as e:
        raise Exception(f"ä¸Šå‚³è³‡æ–™åˆ° Storage æ™‚å¤±æ•—: {e}")

def convert_pcm_to_wav_in_memory(pcm_data: bytes, channels: int = 1, sample_width: int = 2, frame_rate: int = 24000) -> bytes:
    """å°‡ raw PCM éŸ³è¨Šè³‡æ–™åœ¨è¨˜æ†¶é«”ä¸­è½‰æ›ç‚º WAV æ ¼å¼"""
    with io.BytesIO() as wav_file:
        with wave.open(wav_file, 'wb') as wf:
            wf.setnchannels(channels)
            wf.setsampwidth(sample_width)
            wf.setframerate(frame_rate)
            wf.writeframes(pcm_data)
        return wav_file.getvalue()

def create_paper_output_folder(arxiv_id: str) -> Path:
    """ç‚ºå–®ç¯‡è«–æ–‡å‰µå»ºå°ˆç”¨çš„æœ¬åœ°è¼¸å‡ºè³‡æ–™å¤¾"""
    output_base = Path(ARXIV_SEARCH_CONFIG.get("output_base_folder", "Podcast_output"))
    paper_folder = output_base / arxiv_id
    paper_folder.mkdir(parents=True, exist_ok=True)
    print(f"ğŸ“ å·²å‰µå»ºæœ¬åœ°è¼¸å‡ºè³‡æ–™å¤¾: {paper_folder}")
    return paper_folder

def insert_paper_to_db(client: Client, paper_data: dict):
    """å°‡è™•ç†å®Œçš„è«–æ–‡è³‡è¨Šæ’å…¥åˆ° Supabase è³‡æ–™åº«ä¸­"""
    try:
        response = client.table("papers").insert(paper_data).execute()
        if len(response.data) == 0:
            raise Exception("æ’å…¥è³‡æ–™å¤±æ•—ï¼Œæ²’æœ‰å›å‚³è³‡æ–™ã€‚")
        print(f"âœ… æˆåŠŸå°‡è«–æ–‡ '{paper_data['title']}' æ’å…¥åˆ°è³‡æ–™åº«")
        return response.data[0]
    except Exception as e:
        raise Exception(f"æ’å…¥è³‡æ–™åº«æ™‚å¤±æ•—: {e}")

def main_workflow():
    """å®Œæ•´çš„å·¥ä½œæµç¨‹"""
    print("ğŸš€ é–‹å§‹åŸ·è¡Œæ¯æ—¥è«–æ–‡æ’­å®¢ç”Ÿæˆå·¥ä½œæµç¨‹...")
    
    try:
        # 1. åˆå§‹åŒ–
        supabase = init_supabase_client()
        podcast_generator = PaperPodcastGenerator()
        
        # 2. æœå°‹æœ€æ–°çš„è«–æ–‡
        print("\nğŸ” æ­£åœ¨å¾ arXiv æœå°‹æœ€æ–°è«–æ–‡...")
        latest_papers = search_latest_ai_paper(
            query=ARXIV_SEARCH_CONFIG["query"],
            max_results=ARXIV_SEARCH_CONFIG["max_results"]
        )
        if not latest_papers:
            print("æ²’æœ‰æ‰¾åˆ°æ–°çš„è«–æ–‡ã€‚å·¥ä½œæµç¨‹çµæŸã€‚")
            return

        for paper in latest_papers:
            arxiv_id = paper['arxiv_id']
            pdf_url = paper['pdf_url']
            print(f"\nğŸ“„ æ‰¾åˆ°è«–æ–‡: {paper['title']} (ID: {arxiv_id})")

            # 3. æª¢æŸ¥è«–æ–‡æ˜¯å¦å·²å­˜åœ¨
            if check_paper_exists(supabase, arxiv_id):
                print(f"âœ… é€™ç¯‡è«–æ–‡ (ID: {arxiv_id}) å·²ç¶“åœ¨è³‡æ–™åº«ä¸­ï¼Œè·³éè™•ç†ã€‚")
                continue

            # 4. è™•ç†æ–°è«–æ–‡
            print(f"âœ¨ æ‰¾åˆ°æ–°è«–æ–‡ï¼Œé–‹å§‹ç”Ÿæˆ Podcast...")
            try:
                # ç”Ÿæˆ Podcast å…§å®¹å’Œæª”æ¡ˆ
                podcast_result = podcast_generator.process_paper(pdf_url=pdf_url)
                paper_info: PaperInfo = podcast_result['paper_info']

                # åœ¨ä¸Šå‚³å‰ï¼Œå…ˆåœ¨æœ¬åœ°å„²å­˜æ‰€æœ‰æª”æ¡ˆ
                output_folder = create_paper_output_folder(arxiv_id)

                # å„²å­˜è«–æ–‡è³‡è¨Š
                info_path = output_folder / f"{arxiv_id}_info.json"
                with open(info_path, 'w', encoding='utf-8') as f:
                    json.dump(paper_info.model_dump(), f, ensure_ascii=False, indent=4)
                print(f"ğŸ“„ è«–æ–‡è³‡è¨Šå·²å„²å­˜åˆ°: {info_path}")

                # å„²å­˜é€å­—ç¨¿
                script_path = output_folder / f"{arxiv_id}_script.txt"
                script_path.write_text(podcast_result['script'], encoding='utf-8')
                print(f"ğŸ“ é€å­—ç¨¿å·²å„²å­˜åˆ°: {script_path}")

                # å°‡ raw PCM éŸ³è¨Šè½‰æ›ç‚º WAV æ ¼å¼
                print("ğŸ™ï¸ æ­£åœ¨å°‡éŸ³è¨Šè½‰æ›ç‚º WAV æ ¼å¼...")
                wav_data = convert_pcm_to_wav_in_memory(podcast_result['audio_data'])
                
                # å„²å­˜éŸ³æª”
                audio_path = output_folder / f"{arxiv_id}.wav"
                with open(audio_path, 'wb') as f:
                    f.write(wav_data)
                print(f"ğŸµ éŸ³æª”å·²å„²å­˜åˆ°: {audio_path}")

                # 5. ä¸Šå‚³éŸ³æª”åˆ° Supabase Storage
                print("â˜ï¸ æ­£åœ¨ä¸Šå‚³éŸ³æª”åˆ° Supabase Storage...")
                bucket_name = SUPABASE_CONFIG["bucket_name"]
                audio_dest_path = f"{arxiv_id}.wav"
                audio_url = upload_to_storage(supabase, bucket_name, audio_dest_path, wav_data)
                print(f"ğŸ”— éŸ³æª” URL: {audio_url}")

                # 6. æº–å‚™è³‡æ–™ä¸¦å¯«å…¥è³‡æ–™åº«
                db_record = {
                    "arxiv_id": arxiv_id,
                    "title": paper_info.title,
                    "authors": paper.get('authors', []),
                    "publish_date": paper.get('updated').isoformat(),
                    "summary": paper_info.abstract,
                    "full_text": podcast_result['script'],
                    "category": paper.get('category'),
                    "tags": paper_info.tags,
                    "innovations": paper_info.innovations,
                    "method": paper_info.method,
                    "results": paper_info.results,
                    "arxiv_url": paper.get('arxiv_url'),
                    "pdf_url": pdf_url,
                    "audio_url": audio_url,
                    "duration_seconds": podcast_result.get('duration_seconds'),
                    # "podcast_title": podcast_result['podcast_title'],
                    # "podcast_script": podcast_result['script'],
                }
                
                insert_paper_to_db(supabase, db_record)
                print(f"ğŸ‰ æˆåŠŸè™•ç†ä¸¦å„²å­˜è«–æ–‡: {paper_info.title}")

            except Exception as e:
                print(f"è™•ç†è«–æ–‡ {arxiv_id} æ™‚ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {e}")
                # å³ä½¿å–®ç¯‡è«–æ–‡å¤±æ•—ï¼Œä¹Ÿç¹¼çºŒè™•ç†ä¸‹ä¸€ç¯‡
                continue
            
            # é è¨­åªè™•ç†ä¸€ç¯‡è«–æ–‡
            break

    except Exception as e:
        print(f"ğŸ˜­ å·¥ä½œæµç¨‹åŸ·è¡Œå¤±æ•—: {e}")

    print("\nğŸ å·¥ä½œæµç¨‹åŸ·è¡Œå®Œç•¢ã€‚")

if __name__ == "__main__":
    main_workflow() 